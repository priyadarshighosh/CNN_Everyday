{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing OpenCV and Python Libraries"
      ],
      "metadata": {
        "id": "BEqykyjgBbwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "duF0MRIGFEfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spXCkRYb9J2L"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow  #so that we can show the image\n",
        "import cv2       # importing Open CV\n",
        "\n",
        "from google.colab import files    # we are importing the file from the device\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading the image"
      ],
      "metadata": {
        "id": "OTeEVhPwBs3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow # Import the cv2_imshow function from google.colab.patches\n",
        "import cv2\n",
        "\n",
        "image = cv2.imread('duck.jpg')\n",
        "print( image )        # this will print the matrix of the image\n",
        "\n",
        "cv2_imshow(image) # Use cv2_imshow instead of cv2.imshow"
      ],
      "metadata": {
        "id": "dcc3Ji6tvu0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it is a color image thats it gave 3 matrices for each pixel  "
      ],
      "metadata": {
        "id": "EBIiIvc-wzMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shape of the image"
      ],
      "metadata": {
        "id": "hdLo4ZEeyqjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "YOpZHlv1yn8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting to Grey Scale Image"
      ],
      "metadata": {
        "id": "ikr1S4un0o3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray_image)"
      ],
      "metadata": {
        "id": "y58mkjD70pQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of the grey scale image"
      ],
      "metadata": {
        "id": "qYfP_69B1_0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray_image.shape   # 550 x 367 that means it is 2153 x 2237 x 1 ... as it has ONLY COLOR CHANNEL"
      ],
      "metadata": {
        "id": "gy1RjsxN2AJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the Gray Scale Image"
      ],
      "metadata": {
        "id": "_lDYpGyu041S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imwrite('gray_image.jpg', gray_image)"
      ],
      "metadata": {
        "id": "ZKYDuKAj07wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (gray_image)              # matrices value of the grey image"
      ],
      "metadata": {
        "id": "x9bSm7m62uA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the Image to Saffron Scale -- BJP"
      ],
      "metadata": {
        "id": "TQHlFOYq1Xja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orange_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "cv2_imshow(orange_image)"
      ],
      "metadata": {
        "id": "455ntiI_1Vip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orange_image.shape      # Color channel is 3 , thats why it is showing 550 x 367 x 3"
      ],
      "metadata": {
        "id": "MyiEShRf1-V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (orange_image)      # matrix value of the orange image"
      ],
      "metadata": {
        "id": "0DWfnEDw3ytG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edge Detection"
      ],
      "metadata": {
        "id": "yeBJXM7bqXab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sobel_horizontal = np.array([\n",
        "    [1, 2, 1],\n",
        "    [0, 0, 0],\n",
        "    [-1, -2, -1]\n",
        "])                           # sobel horizontal filter\n",
        "\n",
        "sobel_vertical = np.array([\n",
        "    [1, 0, -1],\n",
        "    [2, 0, -2],\n",
        "    [1, 0, -1]\n",
        "])                           # sobel vertical  filter"
      ],
      "metadata": {
        "id": "myJXTrp7qXxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sobel_horizontal"
      ],
      "metadata": {
        "id": "vUVDWRcSF8h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sobel_vertical"
      ],
      "metadata": {
        "id": "VzcyyUt_F_G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "GiWspk0jHTGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to do it on grey scale image instead of colorful image as grey scale image has 1 layer so we can take 2 features like rows and columns\n",
        "\n",
        "But for colorful image there are 3 layers so then we can put it in 3 features like rows1 , cols1 and layer"
      ],
      "metadata": {
        "id": "X-5OM2MXItsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows , cols = gray_image.shape\n",
        "rows , cols"
      ],
      "metadata": {
        "id": "XNKi4QqZHiQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = sobel_vertical.shape[0]\n",
        "k"
      ],
      "metadata": {
        "id": "qvscZWD8IZm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows1 , cols1 , layer = orange_image.shape\n",
        "rows1 , cols1 , layer"
      ],
      "metadata": {
        "id": "qgk28twjN9MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning Output matrix as 0"
      ],
      "metadata": {
        "id": "KVBUbqYjpwxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_matrix = np.zeros((rows - k + 1, cols - k + 1))\n",
        "output_matrix"
      ],
      "metadata": {
        "id": "emn8MIlip14d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Main Operation for Edge Detection"
      ],
      "metadata": {
        "id": "WbKoEyqVrLsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8Q-3PmUirRmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1 , rows - 1):\n",
        "\n",
        "\n",
        "    for j in range(1 ,cols -1):\n",
        "        region =  gray_image[i-1:i+2, j-1:j+2]\n",
        "\n",
        "        output_matrix[i-1, j-1] = np.sum(region * sobel_vertical)\n"
      ],
      "metadata": {
        "id": "4lSwfcfhrR_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_matrix"
      ],
      "metadata": {
        "id": "BWYAr_CYtOnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using OPEN CV Functions"
      ],
      "metadata": {
        "id": "FWnWrgQ1q0Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files    # we are importing the file from the device\n",
        "uploaded = files.upload()\n",
        "\n",
        "image = cv2.imread('duck.jpg' , cv2.IMREAD_GRAYSCALE)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "zmKN8ZGqq_Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sobel_horizontall = np.array([\n",
        "    [+1,+2,+1],\n",
        "    [0, 0, 0],\n",
        "    [-1, -2, -1]\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "sobel_output = cv2.filter2D(image, -1, sobel_horizontal)\n",
        "\n",
        "cv2_imshow(sobel_output)  # showing the output image\n",
        "sobel_output.shape"
      ],
      "metadata": {
        "id": "kgjVC7LfuUhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VkDiuwj9vLHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sobel_output = cv2.filter2D(image, -1, sobel_vertical)\n",
        "\n",
        "cv2_imshow(sobel_output)  # showing the output image\n",
        "sobel_output.shape"
      ],
      "metadata": {
        "id": "loUa-aZouGgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a difference we can see between the horizontal edge detection and vertical edge detection"
      ],
      "metadata": {
        "id": "yLAR_GbQvM9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IN HORIZONTAL EDGE DETECTION -- WHITE BORDER IS MORE PROMINENT  ON THE UPPER SIDE , THAT IS IN THE HORIZONTAL PART  ( GOING FROM UP TO DOWN )"
      ],
      "metadata": {
        "id": "hXI1vUanvUt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IN VERTICAL EDGE DETECTION  -- WHITE BORDERS ARE MORE PROMINENT  VERTICALLY THAT IS GOING FROM ( LEFT TO RIGHT )"
      ],
      "metadata": {
        "id": "bRY_ckVnvrtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We going to Use  Different Edge Detectors / Kernels\n",
        "\n",
        "\n",
        "*   Identity kernel\n",
        "*   Edge Detection\n",
        "*   Sharpen kernel\n",
        "*   Box Blur\n",
        "*   Gaussian Blur Kernel\n",
        "\n"
      ],
      "metadata": {
        "id": "6BeUz-UVwTbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identity Kernel returns the Same image as output"
      ],
      "metadata": {
        "id": "ELST4U1KxgQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Identity_kernel = np.array([\n",
        "    [0,0,0],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 0]\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "output = cv2.filter2D(image, -1, Identity_kernel)\n",
        "\n",
        "cv2_imshow(output)  # showing the output image\n",
        "output.shape"
      ],
      "metadata": {
        "id": "BZmm01YvxBp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us the entire edge of the following image\n",
        "Not Horizontal , Not vertical but the entire thing at once ."
      ],
      "metadata": {
        "id": "Jw2fCBpNyHk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edge_detection = np.array([\n",
        "    [-1,-1,-1],\n",
        "    [-1, 8 , -1],\n",
        "    [-1, -1, -1]\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "output = cv2.filter2D(image, -1, edge_dectection)\n",
        "\n",
        "cv2_imshow(output)  # showing the output image\n",
        "output.shape"
      ],
      "metadata": {
        "id": "2bxSlTW5xr62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS the name suggest this makes the Image sharper ."
      ],
      "metadata": {
        "id": "smRNSEjJy0Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sharpen_kernel = np.array([\n",
        "    [0,-1,0],\n",
        "    [-1,5,-1],\n",
        "    [0, -1,0]\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "output = cv2.filter2D(image, -1, sharpen_kernel)\n",
        "\n",
        "cv2_imshow(output)  # showing the output image\n",
        "output.shape"
      ],
      "metadata": {
        "id": "_qoUOoYuyin6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the name suggest , Box- Blur  , it blurs the image of the following  image ."
      ],
      "metadata": {
        "id": "Yy9lE36gy94a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "box_blur = (1/9) * np.array([\n",
        "    [1,1,1],\n",
        "    [1,1,1],\n",
        "    [1 ,1,1]\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "output = cv2.filter2D(image, -1, box_blur)\n",
        "\n",
        "cv2_imshow(output)  # showing the output image\n",
        "output.shape"
      ],
      "metadata": {
        "id": "XLTyWtgZy-MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gausian Blur is also another Kind of Blur that we use for edge detection ."
      ],
      "metadata": {
        "id": "arXEhBZ-zj6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gaussian_blur_kernel = (1/256) * np.array([\n",
        "   [1,4,6,4,1],\n",
        "   [4,16,24,16,4],\n",
        "   [6,24,36,24,6],\n",
        "   [4,16,24,16,4],\n",
        "   [1,4,6,4,1]])\n",
        "\n",
        "\n",
        "\n",
        "output = cv2.filter2D(image, -1, gaussian_blur_kernel)\n",
        "\n",
        "cv2_imshow(output)  # showing the output image\n",
        "output.shape"
      ],
      "metadata": {
        "id": "KSGz6SaqzjV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}